Friends, in this video we will try to understand what is normal distribution or gaussian distribution. These two are terms for the same thing. We'll also understand what is z score and we'll do some python coding to understand how exactly these concepts are used in the field of data science and machine learning. So let's get started. Let's say you want to do data analysis on people's height data set. You would be wondering what kind of analysis you can do. Say you are a data scientist working for a clothing store and to produce the clothes of certain size the clothing company has assigned you this task. As a data scientist you want to do some analysis on people's heights. Now when you plot these heights on a histogram, it will look like this. What is histogram? Histogram is a frequency distribution. For example, you have three data samples between height five and 5.5. So what are those samples? Well, 5.15.25. .4 so you are just plotting the height and the counts of those samples on this simple chart which is known as a histogram. And when you draw a curve that passes through this histogram, this curve looks like a bell. You know, you might have seen a bell in a church or a temple. And that's why this curve is known as a bell curve. So this is what normal distribution is. In normal distribution you will have most of your data samples around average average value. And then you will have some data samples which are far away from average. On left hand, right hand side, for example, you have some people whose heights are six or maybe around 7ft. You know, you'll have very like small percentage of people whose height will be around seven. Similarly you will have small percentage of people whose height will be, let's say less than 4ft. So the idea is in nature we find many data sets who which follow the normal distribution. For example, let's say you are looking at the prices, two bedroom prices of apartment in Bangalore city. Most of the apartments on average they cost around 90 lakh rupees. So you see, let's say I took samples of few thousand property prices and you will see like for 90 lakh rupees I have around 280 data samples. Similarly, you will have very few data samples whose high. Whose price will be on a higher higher end. Okay. And very few data samples whose height will be on a lower end. So most of the values will be centered around average. And then you, as you go far away from the average, the number of data samples reduces. You see the similar behavior when you are examining test scores for a given classroom. Let's say you took mathematics test, you know, and the test is giving you score out of hundred. Let's say your maximum score is 85. You will find very few people who will have high marks and very few people who will have very low marks. Most of the people will have marks in an average range. Another example is employee performance. When they will at employees performance, majority of the employees will have performance in the average category. You will have few best performer and few low performers. So we naturally see normal distribution in many data sets. And therefore, for data scientists and machine learning engineers, knowing normal distribution is very, very important. Now you'll ask me, okay, I understood normal distribution. How can I use this in my real life? How can I use this in data analysis? The classical use case is during data cleaning process. You can use normal distribution and standard deviation. For outlier removal, let's, I use the same data set, but I have added a new data point. Smith, whose height is 9ft. Now, outlier is a data point which, which has a value that is very different from, from your average values. Here. You know, people's height are usually around 6ft, 5ft, but you don't see a person with height 9ft. Okay, so these kind of outliers can occur because of an error in data collection process, or, you know, in data transmission process. Or sometimes you might have valid data points like you. You can have a person whose height, I think the person whose height was maximum in the history, he had a height of 8.7ft or something. So you can have a valid data point as well. But when you plot them on a histogram, you can clearly see that those data points kind of stand out. They are very far away from your normal regular data points. During data science process, you want to treat the outlier. And by treating the outlier, I mean you either want to remove them or you want to apply some other methods to treat them. If you don't treat outliers, it will create problems in your data science process, in your machine learning process. You know, your machine learning model might get skewed because of the presence of these outliers. So it's important that you treat the outliers either by removing them or applying some kind of transformation. Now, here I have a very simple data set. When I have a data set which has less than million data points, just by looking at the data points, I won't know which are outliers. So you need some kind of formula, or you need to apply some math to figure out those outliers. So what formula that is? Well, you need to first understand what is standard deviation. I made a very short video on that. So please go to YouTube, search for code basic standard deviation. Watch that eight minute video once you have understanding of standard deviation. Now, I will explain how statisticians use standard deviation to remove outliers. So here I have same histogram, the bell curve again, and in the middle, you will have a mean point, your average point. On the right hand side, you have. See, this sigma symbol is for standard deviation. So you have plus one standard deviation, plus two standard deviation, plus three, minus one standard deviation, and so on. By conducting so many tests on normal, normally distributed data set, mathematician and statistician found that 68.3% data points in any normal distribution comes in plus and minus one standard deviation. Similarly, 95.5% data points out of all total data points fall under plus two minus two standard deviation range. Similarly, 99.7% fall under plus minus three standard deviation range. Now, you can use this knowledge to remove outliers. General guideline is, if the data point is beyond three standard deviation, so any data point that is greater than plus three standard deviation or minus three standard deviation can be treated as an outlier. This is general guideline. Okay? There is no fixed rule. Sometimes when data points are small, I have seen people using two standard deviation as well. So it's a, it's a matter of, you know, using sense of judgment as a data scientist to figure out the correct formula. But what we'll do is we'll now do some python coding, and we'll use standard deviation to remove the outliers from our data set. I went to this particular Kegel data set. I have downloaded this CSV file. The file has height and weight. I have removed weight from that file. So now, in this file, I have people's height. You know, I have 10,000 such data points where I have different people's height. And I have loaded that into my Jupyter notebook. I have my data frame ready, and if I do df height. So my height is a column. And if I do describe it, tells me I have total 10,000 rows. You know, my standard deviation for this height column is 3.84. I have my min max, and so on. Now, we already saw that we can use plus and minus three standard deviation to figure out these outliers. Now, before we do that, I would like to use Seaborne library to plot the bell curve and the histogram. And the way you do that is you call hist plot function in that you supply your height column and you will say kde is equal to true, which means it will plot this kind of curve as well. If KD is false, it just plots the histogram, you know. So now you can clearly see this is a bell curve. It's a normal distribution. Many times as a data scientist, when you're doing data exploration, you want to plot this kind of histogram to figure out whether the distribution is normal or not. And based on that, you can make certain decision. 80% of time spent by data scientist is in data cleaning process. Because when the data comes, you know, it is often messy, it has errors and it has legitimate outliers. So you want to remove those outliers before building your model. And that's exactly what we are going to do here. So to remove the outlier, first you need to figure out a mean. So let's say mean for my height is 66 and these heights are in inches. So 66.36 inch is my mean and my standard deviation is 3.84. Now, we already saw in the diagram here, where was my diagram that I can use plus and minus three, three standard deviation to remove the outliers. So let's see, if I do mean minus three standard deviation, I will get this number. And if I do mean plus three standard deviation, I get this number. So what I'm saying is any number between 54.8, 277.91 is the valid number. Anything outside that is an outlier. Okay? So in pandas data frame, now, I can do something like, okay, if my DF height is less than this number, then that's an outlier. So I got two data points like that. You know, I will also say that, okay, it is either this condition or, or 77.91, right? So 77.91. So I get five such data points, see, with who has height of 78.09 and so on, I can combine this into one condition. I will say this or that. You know, like DF height. If it is less than this or greater than this, then that's my outlier. So I found total seven outlier out of 10,000 data points. And to remove this outlier, I can create a new data frame called DF no outlier. And I can just, you know, apply a reverse condition. You to just apply reverse condition of this. And what is the reverse condition? Well, the reverse condition is this. So what I'm saying is my regular, my clean data set is something for which the height is greater than 54.82 and less than 77.91. And when I do the shape, obviously. See, I find 9993 because seven data points are outlier. So hooray. As a data scientist, you just did data cleaning, you remove the outliers. And now using this particular data frame, when you build your machine learning model, it's going to be much better. Let's now talk about z score. Well, I will tell you, you already know z score. If you know standard deviation, you already know z score. It is the same concept with a little tweak. Okay, what is that tweak? Here again, I have my bell curve in the middle. I have mean on the right hand side. I have plus one standard deviation, plus two standard deviations. Sigma is for, is the symbol used for standard deviation. If I have a data point here at two standard deviation, then the z score for that data point is two. If I have a data point which is in the middle of two and three standard deviation, let's say 2.5, then the z score for that data point is 2.5. Similarly, if I have data point here between minus one minus two, then the z score of that data point is -1.5 so z score is nothing but how many standard deviation away your data point is from mean. So you understand, right? Like the z score is for every single data point. So you can compute z score for every single data point. And that's what we'll do for this particular data set. See here. For this height column, I took an average which is 5.25. Again, I took standard deviation. For this I found it to be 0.61. Now from every single data point I can subtract average and then divide it by standard deviation. I get my z score. So the formula for G score is every single data point minus average divided by the standard deviation. Okay? So it's pretty simple concept. If you know standard deviation, you already know z score. It's the same concept. There is no rocket science here. Now let's apply z score in our notebook and do the outlier removal. Here again, I have my data frame with all the data points and I want to calculate z score for every single data point. And for that, obviously I need to create a new column. When you do this, it will create a new column called z score. And what is that column? Well, that column is df height. So you take your individual data point, you subtract mean from it. So you say df height, dot mean, you divide that by the standard deviation. So this is how you get standard deviation. And then when you look at your data frame, I have already added new column called z score. And these are my individual Z score. Now I want to verify how I came up with 1.94, whatever number. Well, it's pretty simple. See, my mean is this, okay, my standard deviation is this for that first data point. And now what I'm going to do is I, I will use the formula, okay, what is my formula? Let's look at my formula, okay, x which is a data point, minus mean divided by standard deviation. So my data point is this, minus mean, okay, mean is this and what is my standard deviation? Standard deviation is this. And when I do that, I get 1.94. See, 1.94. So it's fairly straightforward concept. Now, once you have z score column, it becomes even more easier to remove the outlier. So I will first look at all those data points whose z score is greater than three. See, I found five such data point whose score is greater than three and less than three is two data points, right? So if you want to see, let's say both of these in one shot, then I can say, okay, less than minus three or greater than three and I get same, my seven data points and you can use the same technique. You know, I can say zf, df, no outlier is equal to the reverse condition, you know, the inverse condition. So I will do this, I will replace r with n and this will be like, okay, my z score has to be greater than minus three and less than three. And that's my no outlier. And you find again 9993. So I removed my seven outliers, I got my cleaned up data frame on which I can perform my further data analysis and even I can build machine learning model on top of it. Now comes the most important part of this tutorial which is an exercise. I have given a link of this exercise page. In the video description below you can read the description and work on this exercise. Friends, working on these exercises is very, very important. So I want you to develop the solution yourself and then you can click on this solution link to verify your answer with my answer. I hope this video gave you some understanding of z score and normal distribution. Outlier removal was just one use case. There are many other use cases as well as we progress forward in this particular tutorial series. And by the way, this, the link of this playlist is given in a video description below. So you please check other videos as well. We are learning mathematics and statistics for data science and machine learning in a very, very simple language and by doing a lot of practice as well. So make sure you check other videos as well. And if you have a friend who thinks that math and statistics is hard. Well, try to share these, this playlist with them so that they can remove that bias. These things are not that hard, actually. You just need to have some discipline, learn the concepts in a clear, simple way, and then practice on Python. Okay, so I hope this was useful. Thank you very much for watching this.