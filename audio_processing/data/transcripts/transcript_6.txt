We will look into two different approaches of saving a trend model to a file, which you can use later on to load the model from a file into a memory and use that to make actual predictions. Solving a problem using machine learning consists of two steps. Typically the first step is training a model using your training data set. And the second step is to ask your questions to the training trained model, which sort of looks like a human brain and that will give you the answers. Often the size of the training data set is pretty huge because as the size increases your model becomes more accurate. It is like if you are doing a football training and if you train yourself more and more, you become more and more better at your football game. And when your training data set is so huge, often it is in like gigabytes. The training step becomes more time consuming. If you save the train model to a file, you can later on use that same model to make the actual prediction. So you don't need to train it every time you want to ask these questions, right? So if you have it saved to a file now I don't have a training step here and I can directly ask a questions. So that's what we are going to look into today. We'll write a python code to save that model to a file. Here I have a Jupyter notebook which I used in my first tutorial of linear regression of predicting home prices. The code here is pretty straightforward. I am loading home prices from my CSV file and then using linear regression to make the actual prediction. And here is saying that 5000 sqft home is going to cost me $859,000. So let's use Python's pickle module. Now you guys might be aware about pickle module already. It allows you to serialize your python object into a file. So here I will use the file. So I'll first say with open model pickle and I'm going to write binary data. Hence I'm using wb mode in the file. So first I am opening a file and then what I will do is I will say pickle dot dump, dump my model into this file. When I run this, what actually happens is in my working directory it created this model pickle file which if I open in my notepad looks like this. This is some gibberish and it is expected to be gibberish because it's a binary file. Okay, you actually don't need to care about the content here, but what you need to know is your model is saved into a file now. Now you can use the same model here. So what I can do is here I can say model is equal to pickledump load the file okay so again I have to open the file pointer. So it's the same file, but this time I am using it in a read mode and it's a binary file. Hence I have supplied b here. Now I have my model I will just say mpdev. So now I have my model loaded from a file into a memory and mp is the object. If I use now Mp object to make the prediction okay I want to ask what is the price of my 5000 sqft home? Then you can see that it will give me the same answer as I got it here at this tab. So this is beautiful because now I can supply this model file to a friend of mine and I can say okay, here is my train model or a trained brain, go use it for your actual problem. Alright, so you can ask the questions to this model and it will give the answers. There is a second approach of saving model to a file which is using Sklearns job lib. So if you google Sklearn model persistent, you will find this link where Sklearn's documentation shows how you can use Joblib to do essentially the same thing. So then if it is doing the same thing, then what's the difference between pickle and Joblib? As per the documentation, if your model consists of large numpy arrays, then using joblib might be more efficient. Now I have not done any profiling myself, but you can go ahead and do it on your own and figure out which one you want to use. But usually people say that when you have a lot of numpy arrays, job Lib tends to be more efficient, but essentially it gives you the same functionality. So I will first import job lib in Jupyter notebook you can hit tab and it will show you the autocomplete. So here there is external modules. From that I will import joblib. Now the difference between joblib API and pickle API is that joblib can take the file name directly. So I have my model and I want to save that model to a file. I will say model job lib when execute this, it saved this model to this particular file and when I go to my working directory I will find this file here it is just updated right now. 631 is the timestamp. When I open that file into not paired I will again see some gibberish because this is also a binary file. Again you don't care about the content here. What you need to know is your model is successfully saved and you can load that model using joblib load give the file name. In return, you get your model object back and that model object you can use to make actual prediction. And it gives you the same answer here. What it is saving inside that binary file is different things such as for example, if you look at coefficient, the coefficient is same as what I got it here, so it's saving all these essential pieces for your model. Okay, that's all I had for this tutorial. I don't have any exercise today, but you can go ahead and save your model using Joblib and pickle into a file. And I have gone through linear regression models today, but you can pretty much save any other kind of machine learning models using these two awesome models.