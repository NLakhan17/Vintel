{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6ee841-a6cc-4854-bdae-d851967b6973",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install moviepy\n",
    "!pip install assemblyai\n",
    "!pip install librosa\n",
    "!pip install pydub\n",
    "!pip install noisereduce\n",
    "!pip install soundfile\n",
    "!pip install huggingface_hub\n",
    "!pip install transformer\n",
    "!pip install evaluate\n",
    "!pip install jiwer\n",
    "!pip install sentencepiece\n",
    "!pip install tensorflow_io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fa7a48-f05a-47aa-96af-aabb765b50fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import *\n",
    "import librosa\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import assemblyai as aai\n",
    "import pandas as pd\n",
    "from pydub import AudioSegment\n",
    "from pydub.silence import split_on_silence\n",
    "import noisereduce as nr\n",
    "import soundfile as sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34ec252-3a8f-424b-8428-db761abcc0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_to_audio():\n",
    "\n",
    "  folder_path = 'C:/Users/Harsh Patel/Desktop/Vintel/videos'\n",
    "  for filename in os.listdir(folder_path):\n",
    "      file_path = os.path.join(folder_path, filename)\n",
    "      if os.path.isfile(file_path) and filename.endswith(('.mp4', '.mov', '.avi', '.mkv')):\n",
    "            print(f\"Processing video file: {filename}\")\n",
    "\n",
    "            # Open the video file and extract audio\n",
    "            videoclip = VideoFileClip(file_path)\n",
    "            audioclip = videoclip.audio\n",
    "\n",
    "            # Write the audio file to mp3 format\n",
    "            audio_output_path = f\"C:/Users/Harsh Patel/Desktop/Vintel/audios/audiofile_{filename.split('.')[0]}.mp3\"\n",
    "            audioclip.write_audiofile(audio_output_path, codec=\"libmp3lame\")\n",
    "            print(f\"Audio saved as: {audio_output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359ab2ea-5124-4811-8c79-788de1c6d58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datasets import Dataset, DatasetDict\n",
    "import soundfile as sf\n",
    "\n",
    "def load_and_preprocess_data(audio_dir, transcript_dir):\n",
    "    data = {'label': [], 'audio': [], 'transcript':[]}\n",
    "\n",
    "    # Process audio files\n",
    "    for index, audio_file in enumerate(os.listdir(audio_dir)):\n",
    "        if audio_file.endswith('.mp3'):  # Adjust for audio file types\n",
    "            file_path = os.path.join(audio_dir, audio_file)\n",
    "\n",
    "            # Assuming preprocess_audio returns the processed audio and sample rate (sr)\n",
    "#             processed_audio, sr = audio_reader(file_path)\n",
    "            processed_audio, sample_rate = librosa.load(file_path, sr=16000, mono=True)\n",
    "\n",
    "            # Append processed audio to the data dictionary\n",
    "            data['audio'].append(processed_audio)\n",
    "\n",
    "    # Process transcript files\n",
    "    for index, transcript_file in enumerate(os.listdir(transcript_dir)):\n",
    "        if transcript_file.endswith('.txt'):  # Adjust for transcript file types\n",
    "            file_path = os.path.join(transcript_dir, transcript_file)\n",
    "\n",
    "            # Read the transcript content and append it\n",
    "            with open(file_path, 'r') as content:\n",
    "                data['transcript'].append(content.read())\n",
    "\n",
    "    # Ensure the label count matches the number of audios/transcripts\n",
    "    num_entries = min(len(data['audio']), len(data['transcript']))  # Match the number of entries\n",
    "    data['audio'] = data['audio'][:num_entries]  # Trim excess audio if necessary\n",
    "    data['transcript'] = data['transcript'][:num_entries]  # Trim excess transcript if necessary\n",
    "\n",
    "    data['label'] = [1] * num_entries  # Create a list of labels (e.g., all set to '1')\n",
    "\n",
    "    return data\n",
    "\n",
    "# Load and preprocess the audio and transcript data\n",
    "audio_data1 = load_and_preprocess_data('/content/sample_data/audios', '/content/sample_data/transcripts')\n",
    "\n",
    "train_dict = {k: v[:8] for k, v in audio_data1.items()}\n",
    "test_dict = {k: v[8:] for k, v in audio_data1.items()}\n",
    "\n",
    "\n",
    "# Convert it into a Hugging Face dataset\n",
    "dataset1 = DatasetDict({\n",
    "    'train': Dataset.from_dict(train_dict),\n",
    "    'test': Dataset.from_dict(test_dict)# Split later into train/test if needed\n",
    "})\n",
    "\n",
    "print(dataset1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85d6b4c-32e6-42f1-989f-9b69eb842b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Wav2Vec2Processor, Wav2Vec2ForCTC, pipeline\n",
    "\n",
    "# Load your fine-tuned model and processor\n",
    "processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "\n",
    "# Create the ASR pipeline with chunking enabled, explicitly providing feature_extractor and tokenizer\n",
    "asr_pipeline = pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model=model,\n",
    "    feature_extractor=processor.feature_extractor,  # Use the feature extractor\n",
    "    tokenizer=processor.tokenizer,  # Use the tokenizer\n",
    "    chunk_length_s=3  # Set chunk length in seconds (e.g., 5 seconds)\n",
    ")\n",
    "\n",
    "# Load the audio file path\n",
    "audio_path = \"/audios/audio_1.mp3\"\n",
    "\n",
    "# Perform inference with chunking and streaming\n",
    "transcription = asr_pipeline(audio_path)\n",
    "\n",
    "# Print the final transcription\n",
    "print(\"Transcription:\", transcription['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ae1231-d331-4aa5-a2f6-957177173004",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c85ae00-833c-424e-9e2e-a990078a8a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import LEDTokenizer, LEDForConditionalGeneration\n",
    "\n",
    "# Load model and tokenizer\n",
    "model_name = \"allenai/led-large-16384\"\n",
    "tokenizer = LEDTokenizer.from_pretrained(model_name)\n",
    "model = LEDForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "# The text to be summarized\n",
    "text = \"\"\"\n",
    "Our cat teacher is going to teach you cosine similarity and cosine distance how it is used in data science. \n",
    "We'll look at some theory and then we'll move into python code. Let's say you are data scientist working for some financial company where on a Google Drive you have bunch of financial documents. Now, you don't know for what is the company associated with each of these documents, but when you open the document, when you read it, you can kind of figure out that this is probably about Apple. \n",
    "Why? Because iPhone is mentioned so many times. So when you're reading about Apple financial report, they might mention Galaxy as well because that's their main competitor. But here the ratio of iPhone to Galaxy is iPhone have iPhone is mentioned three times, Galaxy is mentioned one time. So, you know, overall you see iPhone occurrence more, much more than galaxy. \n",
    "If your Samsung document, of course, Samsung company document will have more mention of Galaxy than iPhone. \n",
    "Now, let's say new document comes in and you don't know what is the company associated with it. \n",
    "Here you can again count iPhone and Galaxy, and you find that iPhone is six times mentioned in the document. Galaxy is mentioned two times. Looking at the situation as a data scientist, you can figure out a simple formula that whenever a ratio of iPhone to galaxy is three to one, it should be an Apple document. So now you can auto annotate Apple as a company. This is a common problem in financial institute where you have a document and you want to tag some metadata to it, and we can use some automation, some rules, some coding to auto annotate. You know, you can manually annotate it, but using this particular formula, you can automate the annotation process. Unfortunately, things in real life are quite different. In our document, you know, there might be a mention of iPad. Google Pixel is another competitor. So now how do you come up with your formula? Maybe you say, okay, iPhone to galaxy ratio has to be three to one and iPhone to pixel ratio has to be three to one and iPad to pixel ratio has to be two to one. Wow, that's too complicated. My baby got confused. Well, vector mathematics comes at rescue. This thing can be presented as a vector here. And using vector mathematics, we can figure out document similarity. Let me go back to the simple case that we saw before. How do you represent this as a vector? On x axis, I have iPhone word count. Y axis has galaxy word count. So you see three, two, one. And this is the vector. Vector has magnitude and direction both. And when I have my yellow document, iPhone is six galaxies, two. Now look at the angle between these two arrows, blue and yellow, the angle is zero. So the angle determines the document similarity. If the angle is zero, it means documents are very similar. You might have another green document. You know, iPhone five, Galaxy one time here, the angle is still not that high. You know, it's a little bit of an angle. So you can say these documents are still similar. But when you have a Samsung document where iPhone is mentioned only once, Galaxy is four, you see the angle is much bigger. So when you have a bigger angle, you can say these documents are not similar. Meaning, if for yellow arrow, I know companies Apple. For blue arrow, I can say companies definitely not Apple. Versus if I have a green arrow where the theta two angle is much, you know, much closer to yellow arrow, you can say green and yellow documents are similar, whereas blue is not similar. Let's say the angle between these two is 17 degree. You can use this angle to define document similarity. One thing you can say is document similarities is 17 degree. Hmm. I mean, when I say that, it doesn't sound that obvious or intuitive. It's not a good way to represent similarity. What if I can present the similarity between some number between, let's say, zero to one? When I say document similarity is 0.9, which means they're 90% similar, you know, if the document similarity is one, they are very similar. If it is zero, they are very different. Okay, so how can you transform this degree angle into a range? Because that range seems like a good convention. You just take cosine. If you don't know about sine cosine. I made a video previously in the same series. Watch that. But cosine of 17 is 0.95. Now see, my convention is much more obvious, much more easier. I can say document similarity here between green and yellow vector is 0.95. Hooray. All right, now, cosine similarity is nothing but a cosine of an angle between the two vectors. And the great part about math is we looked at very simple scenario of two dimensional vector in real life. You will have 100 dimension vector, and these dimensions are basically the features. So your document might have 100 features and you can present those as a vector and you can still do the math. See, that's the beauty of math. \n",
    "You cannot visualize 100 dimension, but the math will continue to work. Okay, the academic formula is between a and b. These are the two vectors. And the cosine similarity between these two vectors is dot product, which is a dot b divided by magnitude of a magnitude of b, and a dot b is usually b cos theta. So you know it is cosine similarity is nothing but cos theta. All right, now if you have arrows pointing in the same direction, then the cosine similarity is one, which means those arrows, those vectors, those documents are quite similar. If they are at 90 degree means the similarity is zero, they are very different. And if it is 180 degree, similarity is minus one, which means they represent opposite concept. Now, cosine distance, a very simple concept, just it is used to represent the same thing. It's one minus cosine similarity. So here when two arrows are pointing in the same direction, when you're talking about same vector, the cosine distance will be zero. So when you say distance is zero, which means they are similar, they are closer. That's the only idea behind cosine distance. When you have two vectors at 90 degree cosine distance is one, which means they are very different. And cosine distances are represented only in a positive space. That's why I'm not talking about that 180 degree case that we saw in a previous slide. Let's write some Python code. Now we'll be using Python's sklearn module for importing cosine similarity method here. And when you have this method, it expects two vectors. And those two vectors are going to be the case that we looked at for apple document was three, one and six and two. So let's see what is the similarity between three, one and six and two. So three, one, six and two. Now this method expects two dimensional array. So you have to put one additional array here. I mean that's the signature of the method. You see similarity is one, which means the documents are very similar. And if you find a cosine distance of the same thing is going to be zero cosine distance. So this is two dimensional, okay, see one e raise two -16 this is very close to zero. Okay, now if you find out a distance between, let's say, these two documents, you know, 3132 see they are iPhone three times the galaxy one times, iPhone three times galaxy two times. Still they both are Apple documents. So there is a 0.96 per similarity. One similarity means they're very, very similar. Now let's look at some real documents. I'm going to create some variable variables here with financial document string. So you can see the first one is iPhone, Apple document, Apple document, Samsung. Samsung. Okay. And what you can do is you can create a pandas data frame. So I'm going to import pandas here and we create a pandas data frame and the data in the data frame, we are going to hard code some arrays. Okay, so what are those records? In the first document, you see, iPhone came one, two, three times, galaxies one time. Okay, so iPhone three times, galaxy one time. Similarly, I have pre counted the iPhone and galaxy word count in remaining documents. And that's, that's what it looks like now in the index, want to supply the document as an index. So instead of 0123, I will say, okay, doc one, doc two, doc three, and my data frame will look like this. So it says document one has iPhone three times, galaxy one times, and so on. You can clearly see, first two documents are Apple documents, and second and third documents are Samsung documents. Now, when you do something like this, it returns you first document, but it is two dimensional array or a data frame. And our cosine similarity function expects that data frame. And that's why we are doing this, you know, otherwise I would have done simply this. I want to compare, let's say document one and document two. So I would have done this, right. But see it, it expects two dimensional array and that's the only reason I am doing this kind of range. Okay, we are getting some error. Let's see. Oh yeah, this is a syntax error. Actually it has to be this way. See, they're very similar. .94 so we can say both are Apple documents. But if you do the same thing with, let's say, document one and document three, they are not that similar. See. .6 why .6 well, let's compare doc one and Doc three. See three, one and one three. There's some similarity, you know, but if you do doc three and four, let's say, then they will be more closer to one. See point 98. And now for the same documents, if I do cosine distance, it will be 0.01. So quotient distance is one minus similarity. So if you add these two numbers, they will add up to one. That's all pretty much I had. If you want to do the same thing in Tensorflow, then Tensorflow has this particular function that you can use. I hope you like this video. If you did, please share it with your friends. Thank you.\n",
    "\"\"\"\n",
    "\n",
    "# Preprocessing the input text for T5\n",
    "input_text = \"summarize: \" + text\n",
    "input_ids = tokenizer.encode(input_text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "\n",
    "# Generate summary (set max_length to control the length of the summary)\n",
    "summary_ids = model.generate(input_ids, max_length=250, num_beams=2, length_penalty=2.0, early_stopping=True)\n",
    "\n",
    "# Decode the generated summary\n",
    "summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "\n",
    "print(\"Summary:\", summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c5697d-3017-4ae3-b90f-e547d6698ae1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a93f794-3579-48ed-8388-139d27406b68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a048dc4-db0f-4b00-84b7-1297adac0b20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e999447-e39c-41b5-9435-2743633dec80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1943a9d1-0f80-458c-9d26-5104698532bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58bca083-9ce8-4a7d-be6a-b08e6b55f454",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eefca81a-48cf-4506-ae12-1eea115e41eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
